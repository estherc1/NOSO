sapply(states, sd)
cor(states)
#Basic graphical EDA for the states dataset.
plot(states)
shinyServer(function(input, output)({
output$Studiobased <- renderPlot({
studiobasedfinal%>%filter(studio %in% input$Studio1)%>%
ggplot(., aes(x = studio, y = value))+geom_bar(aes(fill = avgtype), stat = "identity", position = "dodge")
})
output$Time <- renderPlot({
})
# show map using googleVis
output$Summary <- renderGvis({
})
# show histogram using googleVis
output$VideoCategories <- renderPlot({
})
plotOutput("VideoCategories", width = 700, height = 500)
# show data using DataTable
output$table <- DT::renderDataTable({
})
# show statistics using infoBox
output$SumBox <- renderInfoBox({
})
output$SumBox5 <- renderInfoBox({
TotalDislikes <- format(sum(RegionSummary$TotalDis), big.mark = ",")
Total_Dislikes <- "Total Number of Dislikes"
infoBox(Total_Dislikes, TotalDislikes, icon = icon("thumbs-down"), fill = T, color = "green")
})
output$SumBox6 <- renderInfoBox({
})
}))
library(shiny)
library(googleVis)
library(ggplot2)
library(ggthemes)
library(dplyr)
getwd()
getwd()
shiny::runApp('C:/Users/Bird_/Desktop/Project2_1')
View(Rot_IMDB)
View(Rot_IMDB)
runApp('C:/Users/Bird_/Desktop/Project2_1')
runApp('C:/Users/Bird_/Desktop/Project2_1')
runApp('C:/Users/Bird_/Desktop/Project2_1')
runApp('C:/Users/Bird_/Desktop/Project2_1')
runApp('C:/Users/Bird_/Desktop/Project2_1')
runApp('C:/Users/Bird_/Desktop/Project2_1')
runApp('C:/Users/Bird_/Desktop/Project2_1')
runApp('C:/Users/Bird_/Desktop/Project2_1')
runApp('C:/Users/Bird_/Desktop/Project2_1')
runApp('C:/Users/Bird_/Desktop/Project2_1')
Rot_IMDB %>%
filter(Type == "IMDB_User") %>%
ggplot(aes(x = title, y = Rating))+ geom_point(aes(color = Types)) + coord_cartesian(ylim=c(50,100)) +theme(axis.title.x = element_blank(), axis.text.x = element_blank())
Rot_IMDB %>%
filter(Types == "IMDB_User") %>%
ggplot(aes(x = title, y = Rating))+ geom_point(aes(color = Types)) + coord_cartesian(ylim=c(50,100)) +theme(axis.title.x = element_blank(), axis.text.x = element_blank())
Rot_IMDB %>%
filter("IMDB_User" %in% Types) %>%
ggplot(aes(x = title, y = Rating))+ geom_point(aes(color = Types)) + coord_cartesian(ylim=c(50,100)) +theme(axis.title.x = element_blank(), axis.text.x = element_blank())
Rot_IMDB %>%
filter("IMDB_User" in Types) %>%
ggplot(aes(x = title, y = Rating))+ geom_point(aes(color = Types)) + coord_cartesian(ylim=c(50,100)) +theme(axis.title.x = element_blank(), axis.text.x = element_blank())
Rot_IMDB %>%
filter(Types == c("IMDB_User", "imdb_critic_rating")) %>%
ggplot(aes(x = title, y = Rating))+ geom_point(aes(color = Types)) + coord_cartesian(ylim=c(50,100)) +theme(axis.title.x = element_blank(), axis.text.x = element_blank())
runApp('C:/Users/Bird_/Desktop/Project2_1')
runApp('C:/Users/Bird_/Desktop/Project2_1')
shiny::runApp('C:/Users/Bird_/Desktop/Project2_1')
##############################
#####Classification Trees#####
##############################
#Loading the tree library for fitting classification and regression trees.
library(tree)
#Loading the ISLR library in order to use the Carseats dataset.
library(ISLR)
#Making data manipulation easier.
help(Carseats)
attach(Carseats)
#Looking at the variable of interest, Sales.
hist(Sales)
summary(Sales)
#Creating a binary categorical variable High based on the continuous Sales
#variable and adding it to the original data frame.
High = ifelse(Sales <= 8, "No", "Yes")
Carseats = data.frame(Carseats, High)
#Fit a tree to the data; note that we are excluding Sales from the formula.
tree.carseats = tree(High ~ . - Sales, split = "gini", data = Carseats)
summary(tree.carseats)
#Plotting the classification tree.
plot(tree.carseats)
text(tree.carseats, pretty = 0) #Yields category names instead of dummy variables.
#Detailed information for the splits of the classification tree.
tree.carseats
#Splitting the data into training and test sets by an 70% - 30% split.
set.seed(0)
train = sample(1:nrow(Carseats), 7*nrow(Carseats)/10) #Training indices.
View(train)
Carseats.test = Carseats[-train, ] #Test dataset.
High.test = High[-train] #Test response.
View(High.test)
#Ftting and visualizing a classification tree to the training data.
tree.carseats = tree(High ~ . - Sales, data = Carseats, subset = train)
plot(tree.carseats)
text(tree.carseats, pretty = 0)
summary(tree.carseats)
tree.carseats
#Using the trained decision tree to classify the test data.
tree.pred = predict(tree.carseats, Carseats.test, type = "class")
tree.pred
summary(tree.pred)
#Assessing the accuracy of the overall tree by constructing a confusion matrix.
table(tree.pred, High.test)
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(ISLR)
help(OJ)
attach(OJ)
summary(OJ)
summary(OJ)
View(OJ)
set.seed(0)
OJ.Train = sample(1:nrow(OJ), 8*nrow(OJ)/10)
OJ.Test = OJ[-OJ.Train,]
#Train
tree.OJ = tree(split = "gini", data = OJ, subset = train)
plot(tree.OJ)
summary(tree.OJ)
#Test
tree.OJPred = predict(tree.OJ, OJ.Test, type = "class")
tree.OJPred
table(tree.OJPred, OJ.Test)
#Assessing the accuracy of the overall tree by constructing a confusion matrix.
table(tree.pred, High.test)
OJ.Test = OJ[-OJ.Train, ]
#Train
tree.OJ = tree(split = "gini", data = OJ, subset = train)
#Test
tree.OJPred = predict(tree.OJ, OJ.Test, type = "class")
tree.OJPred
table(tree.OJPred, OJ.Test)
View(Carseats)
#Test
View(OJ)
View(Carseats.test)
View(High.test)
View(Carseats.test)
OJ.Train = sample(1:nrow(OJ), 8*nrow(OJ)/10)
OJ.Test = OJ[-OJ.Train, ]
Purchase.Test = Purchase[-OJ.Train]
#Train
tree.OJ = tree(split = "gini", data = OJ, subset = train)
plot(tree.OJ)
summary(tree.OJ)
#Test
View(OJ)
table(tree.OJPred, Purchase.Test)
View(Purchase.Test)
View(High.test)
accuracy = (89+41)/214
accuracy
#Performing cross-validation in order to decide how many splits to prune; using
set.seed(0)
cv.OJ = cv.tree(tree.OJ, FUN = prune.misclass)
#Inspecting cv.OJ
names(cv.OJ)
cv.OJ
par(mfrow = c(1, 2))
plot(cv.OJ$size, cv.OJ$dev, type = "b",
xlab = "Terminal Nodes", ylab = "Misclassified Observations")
plot(cv.OJ$k, cv.OJ$dev, type  = "b",
xlab = "Alpha", ylab = "Misclassified Observations")
par(mfrow = c(1, 1))
prune.OJ = prune.misclass(tree.OJ, best = 5)
plot(prune.OJ)
plot(cv.OJ$size, cv.OJ$dev, type = "b",
xlab = "Terminal Nodes", ylab = "Misclassified Observations")
plot(cv.boston$k, cv.boston$dev, type  = "b",
xlab = "Alpha", ylab = "RSS")
plot(cv.OJ$k, cv.OJ$dev, type  = "b",
xlab = "Alpha", ylab = "RSS")
Purchase.Train = Purchase[-OJ.Train]
table(tree.OJPred, Purchase.Train)
View(Purchase.Train)
OJ.Train = sample(1:nrow(OJ), 8*nrow(OJ)/10)
Purchase.Train = Purchase[-OJ.Train]
View(Purchase.Train)
OJ.Test = OJ[-OJ.Train, ]
Purchase.Test = Purchase[-OJ.Train]
View(Purchase.Test)
accuracy.training =(89+41)/214
table(tree.OJ, Purchase.Train)
table(tree.OJPred, Purchase.Train)
table(tree.OJPred, Purchase.Test)
accuracy = (89+41)/214
accuracy
table(tree.OJPred, Purchase.Test)
accuracy = (98+48)/214
accuracy
set.seed(0)
OJ.Train = sample(1:nrow(OJ), 8*nrow(OJ)/10)
OJ.Test = OJ[-OJ.Train, ]
Purchase.Test = Purchase[-OJ.Train]
View(Purchase.Test)
#Train
tree.OJ = tree(split = "gini", data = OJ, subset = train)
tree.OJPred = predict(tree.OJ, OJ.Test, type = "class")
table(tree.OJPred, Purchase.Test)
set.seed(0)
OJ.Train = sample(1:nrow(OJ), 8*nrow(OJ)/10)
OJ.Test = OJ[-OJ.Train, ]
Purchase.Test = Purchase[-OJ.Train]
#Train
tree.OJ = tree(split = "gini", data = OJ, subset = train)
plot(tree.OJ)
summary(tree.OJ)
tree.OJPred = predict(tree.OJ, OJ.Test, type = "class")
tree.OJPred
table(tree.OJPred, Purchase.Test)
accuracy = (98+48)/214
accuracy = (107+54)/214
accuracy
#Performing cross-validation in order to decide how many splits to prune; using
set.seed(0)
cv.OJ = cv.tree(tree.OJ, FUN = prune.misclass)
#Inspecting cv.OJ
names(cv.OJ)
par(mfrow = c(1, 2))
plot(cv.OJ$size, cv.OJ$dev, type = "b",
xlab = "Terminal Nodes", ylab = "Misclassified Observations")
plot(cv.OJ$k, cv.OJ$dev, type  = "b",
xlab = "Alpha", ylab = "Misclassified Observations")
par(mfrow = c(1, 1))
prune.OJ = prune.misclass(tree.OJ, best = 5)
plot(prune.OJ)
plot(cv.OJ$size, cv.OJ$dev, type = "b",
xlab = "Terminal Nodes", ylab = "Misclassified Observations")
plot(cv.OJ$k, cv.OJ$dev, type  = "b",
xlab = "Alpha", ylab = "RSS")
prune.boston = prune.tree(tree.OJ, best = 4)
par(mfrow = c(1, 1))
prune.boston = prune.tree(tree.OJ, best = 5)
prune.OJ = prune.tree(tree.OJ, best = 5)
table(prune.OJ, Purchase.Test)
prune.OJ = prune.tree(tree.OJPred, best = 5)
prune.OJ = prune.tree(tree.OJ, best = 5)
par(mfrow = c(1, 1))
plot(prune.boston)
text(prune.boston, pretty = 0)
table(prune.OJ, Purchase.Test)
table(prune.OJ, Purchase.Test)
set.seed(0)
OJ.Train = sample(1:nrow(OJ), 8*nrow(OJ)/10)
OJ.Test = OJ[-OJ.Train, ]
View(Purchase.Test)
#Train
tree.OJ = tree(split = "gini", data = OJ, subset = train)
tree.OJPred = predict(tree.OJ, OJ.Test, type = "class")
tree.OJPred
table(tree.OJPred, Purchase.Test)
accuracy = (107+54)/214
accuracy
#Performing cross-validation in order to decide how many splits to prune; using
set.seed(0)
cv.OJ = cv.tree(tree.OJ, FUN = prune.misclass)
#Inspecting cv.OJ
names(cv.OJ)
cv.OJ
par(mfrow = c(1, 2))
plot(cv.OJ$size, cv.OJ$dev, type = "b",
xlab = "Terminal Nodes", ylab = "Misclassified Observations")
plot(cv.OJ$k, cv.OJ$dev, type  = "b",
xlab = "Alpha", ylab = "Misclassified Observations")
par(mfrow = c(1, 1))
prune.OJ = prune.misclass(tree.OJ, best = 5)
plot(prune.OJ)
plot(cv.OJ$size, cv.OJ$dev, type = "b",
xlab = "Terminal Nodes", ylab = "Misclassified Observations")
plot(cv.OJ$k, cv.OJ$dev, type  = "b",
xlab = "Alpha", ylab = "RSS")
prune.OJ1 = prune.tree(tree.OJ, best = 5)
par(mfrow = c(1, 1))
table(prune.OJ1, Purchase.Test)
plot(prune.OJ1)
table(prune.OJ1, Purchase.Test)
plot(prune.OJ1)
table(prune.OJ1, Purchase.Test)
prune.OJ1 = prune.tree(tree.OJPred, best = 5)
prune.OJ = prune.misclass(tree.OJ)
plot(prune.OJ)
tree.pred1 = predict(prune.OJ1, Carseats.test, type = "class")
table(prune.pred1, Purchase.Test)
table(tree.pred1, Purchase.Test)
tree.pred1 = predict(prune.OJ1, OJ.test, type = "class")
tree.pred1 = predict(prune.OJ1, OJ.Test, type = "class")
table(tree.pred1, Purchase.Test)
accuracy1 = (108+48)/214
accuracy1
set.seed(0)
OJ.Train = sample(1:nrow(OJ), 8*nrow(OJ)/10)
OJ.Test = OJ[-OJ.Train, ]
Purchase.Test = Purchase[-OJ.Train]
#Train
tree.OJ = tree(split = "gini", data = OJ, subset = train)
tree.OJPred = predict(tree.OJ, OJ.Test, type = "class")
table(tree.OJPred, Purchase.Test)
accuracy = (107+54)/214
accuracy
```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message=FALSE)
library(ISLR)
help(OJ)
attach(OJ)
summary(OJ)
summary(OJ)
View(OJ)
set.seed(0)
OJ.Train = sample(1:nrow(OJ), 8*nrow(OJ)/10)
OJ.Test = OJ[-OJ.Train, ]
Purchase.Test = Purchase[-OJ.Train]
#Train
tree.OJ = tree(split = "gini", data = OJ, subset = train)
##############################
#####Classification Trees#####
##############################
#Loading the tree library for fitting classification and regression trees.
library(tree)
#Loading the ISLR library in order to use the Carseats dataset.
library(ISLR)
library(tree)
#Train
tree.OJ = tree(split = "gini", data = OJ, subset = train)
OJ.Train = sample(1:nrow(OJ), 8*nrow(OJ)/10)
OJ.Test = OJ[-OJ.Train, ]
Purchase.Test = Purchase[-OJ.Train]
View(Purchase.Test)
#Train
tree.OJ = tree(split = "gini", data = OJ, subset = train)
#Train
tree.OJ = tree(split = "gini", data = OJ, subset = OJ.Train)
plot(tree.OJ)
summary(tree.OJ)
tree.OJPred = predict(tree.OJ, OJ.Test, type = "class")
tree.OJPred
table(tree.OJPred, Purchase.Test)
accuracy = (117+53)/214
accuracy
#Performing cross-validation in order to decide how many splits to prune; using
set.seed(0)
cv.OJ = cv.tree(tree.OJ, FUN = prune.misclass)
#Inspecting cv.OJ
names(cv.OJ)
par(mfrow = c(1, 2))
plot(cv.OJ$size, cv.OJ$dev, type = "b",
xlab = "Terminal Nodes", ylab = "Misclassified Observations")
plot(cv.OJ$size, cv.OJ$dev, type = "b",
xlab = "Terminal Nodes", ylab = "Misclassified Observations")
plot(cv.OJ$k, cv.OJ$dev, type  = "b",
xlab = "Alpha", ylab = "Misclassified Observations")
plot(cv.OJ$size, cv.OJ$dev, type = "b",
xlab = "Terminal Nodes", ylab = "Misclassified Observations")
par(mfrow = c(1, 1))
prune.OJ = prune.misclass(tree.OJ, best = 35)
plot(prune.OJ)
plot(cv.OJ$size, cv.OJ$dev, type = "b",
xlab = "Terminal Nodes", ylab = "Misclassified Observations")
plot(cv.OJ$k, cv.OJ$dev, type  = "b",
xlab = "Alpha", ylab = "RSS")
prune.OJ1 = prune.tree(tree.OJPred, best = 35)
prune.OJ1 = prune.tree(tree.OJ, best = 35)
tree.pred1 = predict(prune.OJ1, OJ.Test, type = "class")
table(tree.pred1, Purchase.Test)
accuracy1 = (125+48)/214
accuracy1
library(randomForest)
set.seed(0)
rf.boston = randomForest(data = OJ, subset = OJ.Train, importance = TRUE)
View(Boston)
View(Boston)
##########################
#####Regression Trees#####
##########################
#Inspecting the housing values in the suburbs of Boston.
library(MASS)
help(Boston)
View(Boston)
rf.boston = randomForest(Purchase~, data = OJ, subset = OJ.Train, importance = TRUE)
rf.boston = randomForest(Purchase~., data = OJ, subset = OJ.Train, importance = TRUE)
rf.OJ = randomForest(Purchase~., data = OJ, subset = OJ.Train, importance = TRUE)
rf.OJ
table(rf.OJ, Purchase.Test)
set.seed(0)
oob.err = numeric(13)
rf.OJ
#we are building 500 trees for thirteen times. 500 trees for each predictor. Then, we can reduce back when we see where the optimal is based on SE.
for (mtry in 1:13) {
fit = randomForest(Purchase ~ ., data = OJ[OJ.Train, ], mtry = mtry)
oob.err[mtry] = fit$mse[500]
cat("We're performing iteration", mtry, "\n")
}
(441+237)/856
oob.err = numeric(13)
oob.err = numeric(20)
#we are building 500 trees for thirteen times. 500 trees for each predictor. Then, we can reduce back when we see where the optimal is based on SE.
for (mtry in 1:13) {
fit = randomForest(Purchase ~ ., data = OJ[OJ.Train, ], mtry = mtry)
oob.err[mtry] = fit$mse[500]
cat("We're performing iteration", mtry, "\n")
}
importance(rf.OJ)
varImpPlot(rf.OJ)
install.packages('prophet')
install.packages('FBprophet')
install.packages('prophet')
library(prophet)
install.packages('Rcpp')
install.packages("Rcpp")
install.packages("Rcpp")
install.packages("Rcpp")
library(prophet)
pwd()
getwd()
setwd('C:/Users/Bird_/Desktop/Data-Science-Bootcamp/Capstone/NOSO/Bird')
sale = read.csv('sale_by_week.csv')
View(sale)
library('dplyr')
library('prophet')
install.packages('Rcpp')
install.packages('Rcpp')
install.packages("Rcpp")
install.packages('prophet')
library('prophet')
library('Rcpp')
library('prophet')
library('dplyr')
getwd()
setwd('C:/Users/Bird_/Desktop/Data-Science-Bootcamp/Capstone/NOSO/Bird')
sale = read.csv('sale_by_week.csv')
View(sale)
View(sale)
sample%>%select(., ds,y)%>%
filter(., Style_Color == 'DTA4E2531GRY')
sample%>%select(., ds,y)%>%
filter(., Style_Color == 'DTA4E2531GRY')
sample%>%select(., 'ds','y')%>%
filter(., Style_Color == 'DTA4E2531GRY')
sample%>%
filter(., Style_Color == 'DTA4E2531GRY')%>%
select(., ds,y)
sample%>%
filter(., Style_Color == "DTA4E2531GRY")%>%
select(., ds,y)
sample%>%
filter_(., Style_Color == "DTA4E2531GRY")%>%
select(., ds,y)
sample%>%
dplyr::filter_(., Style_Color == "DTA4E2531GRY")%>%
select(., ds,y)
sample%>%
dplyr::filter(., Style_Color == "DTA4E2531GRY")%>%
select(., ds,y)
sample%>%
filter(., sale.Style_Color == "DTA4E2531GRY")%>%
select(., ds,y)
sale%>%
filter(., Style_Color == "DTA4E2531GRY")%>%
select(., ds,y)
sample = sale%>%
filter(., Style_Color == "DTA4E2531GRY")%>%
select(., ds,y)
sale = read.csv('sale_by_week.csv')
m = prophet(sample, changepoint.prior.scale = 0.02)
forecast = predict(m, future)
future = make_future_dataframe(m, periods=52, freq = 'W')
m = prophet(sample, changepoint.prior.scale = 0.02)
future = make_future_dataframe(m, periods=52, freq = 'W')
m = prophet(sample, changepoint.prior.scale = 0.02)
future = make_future_dataframe(m, periods=52, freq = 'Week')
future = make_future_dataframe(m, periods=52, freq = 'week')
forecast = predict(m, future)
View(forecast)
plot(m, forecast)
prophet_plot_components(m, forecast)
forecast = forecast%>%select(., ds,trend, trend)
forecast
View(forecast)
df.cv <- cross_validation(m, initial = 730, period = 180, horizon = 365, units = 'days')
df.cv <- cross_validation(m, period = 50, horizon = 20, units = 'week')
df.cv <- cross_validation(m, period = 10, horizon = 10, units = 'week')
df.cv <- cross_validation(m, initial = 1, period = 10, horizon = 20, units = 'week')
s
future = make_future_dataframe(m, periods=52, freq = 'weeks')
forecast = predict(m, future)
View(forecast)
forecast = forecast%>%select(., ds,trend, trend)
View(forecast)
prophet_plot_components(m, forecast)
m = prophet(sample, changepoint.prior.scale = 0.02)
future = make_future_dataframe(m, periods=52, freq = 'weeks')
forecast = predict(m, future)
prophet_plot_components(m, forecast)
View(forecast)
forecast = forecast%>%select(., ds,trend)
View(forecast)
View(forecast)
df.cv <- cross_validation(m, initial = 1, period = 41, horizon = 51, units = 'weeks')
df.p <- performance_metrics(df.cv)
head(df.p)
plot_cross_validation_metric(df.cv, metric = 'mape'
plot_cross_validation_metric(df.cv, metric = 'mape')
plot_cross_validation_metric(df.cv, metric = 'mape')
View(df.p)
